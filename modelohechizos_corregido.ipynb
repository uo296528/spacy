{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78dbc604",
   "metadata": {},
   "source": [
    "# Paso 1: Crear el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2acd669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin, Span\n",
    "\n",
    "nlp = spacy.blank(\"es\")\n",
    "\n",
    "train_data = [\n",
    "    (\"Harry dijo Lumos y la sala se iluminó.\", [(11, 16, \"HECHIZO\")]),\n",
    "    (\"Alohomora abrió la puerta mágicamente.\", [(0, 9, \"HECHIZO\")]),\n",
    "    (\"Con un grito de Expecto patronum, un ciervo plateado apareció.\", [(16, 33, \"HECHIZO\")]),\n",
    "    (\"Hermione murmuró Expeliarmo sin dudarlo.\", [(19, 29, \"HECHIZO\")])\n",
    "]\n",
    "\n",
    "doc_bin = DocBin()\n",
    "\n",
    "for text, entities in train_data:\n",
    "    doc = nlp(text)\n",
    "    spans = [Span(doc, doc.char_span(start, end).start, doc.char_span(start, end).end, label=label) \n",
    "             for start, end, label in entities if doc.char_span(start, end) is not None]\n",
    "    doc.ents = spans\n",
    "    doc_bin.add(doc)\n",
    "\n",
    "doc_bin.to_disk(\"train.spacy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da017d9",
   "metadata": {},
   "source": [
    "# Paso 2: Entrenar el modelo con spaCy CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00caf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: es\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config config.cfg --lang es --pipeline ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a1a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     13.33    0.00    0.00    0.00    0.00\n",
      "200     200          0.39    184.02  100.00  100.00  100.00    1.00\n",
      "400     400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "600     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "800     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1000    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1200    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1400    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1600    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1800    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-02 12:41:27,279] [INFO] Set up nlp object from config\n",
      "[2025-05-02 12:41:27,291] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2025-05-02 12:41:27,298] [INFO] Created vocabulary\n",
      "[2025-05-02 12:41:27,298] [INFO] Finished initializing nlp object\n",
      "[2025-05-02 12:41:27,369] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./train.spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b2f21",
   "metadata": {},
   "source": [
    "# Paso 3: Cargar el modelo entrenado y hacer predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9708a948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alohomora 237176 237185 HECHIZO\n",
      "leviosa 253129 253136 HECHIZO\n",
      "leviosa 260629 260636 HECHIZO\n",
      "Alohomora 409597 409606 HECHIZO\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin, Span\n",
    "\n",
    "hechizos = [\n",
    "    \"Expelliarmus\", \"Alohomora\", \"Lumos\", \"Nox\", \"Wingardium Leviosa\", \n",
    "    \"Avada Kedavra\", \"Crucio\", \"Imperio\", \"Expecto Patronum\", \"Sectumsempra\"\n",
    "]\n",
    "\n",
    "nlp = spacy.blank(\"es\")\n",
    "\n",
    "def generar_docs_anotados(texto, hechizos):\n",
    "    doc = nlp(texto)\n",
    "    spans = []\n",
    "    for hechizo in hechizos:\n",
    "        start = 0\n",
    "        while True:\n",
    "            start = texto.lower().find(hechizo.lower(), start)\n",
    "            if start == -1:\n",
    "                break\n",
    "            end = start + len(hechizo)\n",
    "            span = doc.char_span(start, end, label=\"HECHIZO\", alignment_mode=\"contract\")\n",
    "            if span is not None:\n",
    "                spans.append(span)\n",
    "            start = end\n",
    "    doc.ents = spans\n",
    "    return doc\n",
    "\n",
    "# Cargar el libro desde línea 38\n",
    "with open(\"J.K. Rowling - Harry Potter 1 - La Piedra Filosofal.txt\", 'r', encoding='utf-8') as f:\n",
    "    lineas = f.readlines()\n",
    "\n",
    "texto = \"\".join(lineas[37:])\n",
    "doc = generar_docs_anotados(texto, hechizos)\n",
    "\n",
    "# Verificar que los hechizos se anotaron correctamente\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "# Guardar en formato spaCy\n",
    "doc_bin = DocBin()\n",
    "doc_bin.add(doc)\n",
    "doc_bin.to_disk(\"train.spacy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
